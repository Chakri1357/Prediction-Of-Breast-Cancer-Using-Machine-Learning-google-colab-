# -*- coding: utf-8 -*-
"""Breast_Cancer_Prediction_Using_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JXcxNjsqZ46vcNP_-huxQfb3d6GedgQw
"""

print("hello world!")

print("hey!")

#downloading python modules
!pip install numpy
!pip install pandas
!pip install matplotlib
!pip install seaborn
!pip install sklearn

#import the modules
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.preprocessing as sk

df = pd.read_csv('/content/drive/MyDrive/Breast Cancer Prediction Using Machine Learning/data.csv')

df.head()

from google.colab import files
upload = files.upload()

df_1 = pd.read_csv('/content/drive/MyDrive/Breast Cancer Prediction Using Machine Learning/data.csv')

df_1.head()

#EDA -> Exploratory Data Analysis
#Checking the total numbers of Rows and Columns
df.shape

#Checking the Columns and their correspnding data types
#The properties of the data - summary  statistics
df.info()

#2nd way to check for null values
df.isnull().sum()

#drop the column with all missing values
df = df.dropna(axis=1)

df.shape

#Checking data types
df.dtypes

#DATA VISUALIZATION
df['diagnosis'].value_counts()

pd.to_numeric(df['diagnosis'],errors='ignore')

sns.countplot(x='diagnosis',data=df)

from sklearn.preprocessing import LabelEncoder
labelencoder_Y=LabelEncoder()

#transforming categorical into numerical
df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values)

df.iloc[:,1].values

sns.pairplot(df.iloc[:,1:7],hue='diagnosis')

df.iloc[:,1:11].corr()

plt.figure(figsize=(10,10))
sns.heatmap(df.iloc[:,1:11].corr(),annot=True,fmt='.0%')

#Feature Scaling
#split our dataset into independent and dependent data sets
#independent -> x
#depenent -> y
x=df.iloc[:,2:31].values
y=df.iloc[:,1].values

#80:20 ratio
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.20,random_state=0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

x_train

x_test

def models(x_train,y_train):
  from sklearn.linear_model import LogisticRegression
  log=LogisticRegression(random_state=0)
  log.fit(x_train, y_train)

  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion='entropy',random_state=0)
  tree.fit(x_train, y_train)

  from sklearn.ensemble import RandomForestClassifier
  forest=RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)
  forest.fit(x_train, y_train)

  #print the accuracy of each model in the training dataset
  print('The accuracy of Logistic Regression: ',log.score(x_train, y_train))
  print('The accuracy of Decision Tree: ',tree.score(x_train, y_train))
  print('The accuracy of Random Forest: ',forest.score(x_train, y_train))

  return log,tree,forest

model = models(x_train,y_train)

#confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,model[0].predict(x_test))
tp=cm[0][0]
tn=cm[0][1]
fp=cm[1][0]
fn=cm[1][1]
print(cm)
print("accuracy",(tp+tn)/(tp+tn+fp+fn))

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
for i in range(len(model)):
  print('model:',i)
  print(classification_report(y_test,model[i].predict(x_test)))
  print(accuracy_score(y_test,model[i].predict(x_test)))
  print()

#prediction vs. actual prediction 
pred = model[2].predict(x_test)
print('Our Model Prediction: ')
print(pred)
print()
print('Actual Prediction: \n',y_test)